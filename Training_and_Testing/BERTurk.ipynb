{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn torch transformers datasets matplotlib"
      ],
      "metadata": {
        "id": "VnsY2mQvomwR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Install and Import Required Libraries**"
      ],
      "metadata": {
        "id": "d5tFZCAqo2Io"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2S5WHOeoEOV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    precision_recall_curve\n",
        ")\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "from datasets import Dataset as HFDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. **Merge CSV Files for Train, Validation, and Test**"
      ],
      "metadata": {
        "id": "SG8YqMkopFAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change paths accordingly\n",
        "DATA_DIR = \"/content/\"\n",
        "\n",
        "# --- 2.1 Read each dataset's CSVs ---\n",
        "# MT-CSD\n",
        "mtcsd_train = pd.read_csv(os.path.join(DATA_DIR, \"MT-CSD_train.csv\"))\n",
        "mtcsd_dev   = pd.read_csv(os.path.join(DATA_DIR, \"MT-CSD_dev.csv\"))\n",
        "mtcsd_test  = pd.read_csv(os.path.join(DATA_DIR, \"MT-CSD_test.csv\"))\n",
        "\n",
        "# VAST\n",
        "vast_train = pd.read_csv(os.path.join(DATA_DIR, \"VAST_train.csv\"))\n",
        "vast_dev   = pd.read_csv(os.path.join(DATA_DIR, \"VAST_dev.csv\"))\n",
        "vast_test  = pd.read_csv(os.path.join(DATA_DIR, \"VAST_test.csv\"))\n",
        "\n",
        "# Russia-Ukraine_War\n",
        "ruw_train = pd.read_csv(os.path.join(DATA_DIR, \"Russia-Ukraine_War_train.csv\"))\n",
        "ruw_dev   = pd.read_csv(os.path.join(DATA_DIR, \"Russia-Ukraine_War_dev.csv\"))\n",
        "ruw_test  = pd.read_csv(os.path.join(DATA_DIR, \"Russia-Ukraine_War_test.csv\"))\n",
        "\n",
        "# Various_Tweets_(2023)\n",
        "vt_train = pd.read_csv(os.path.join(DATA_DIR, \"Various_Tweets_(2023)_train.csv\"))\n",
        "vt_val   = pd.read_csv(os.path.join(DATA_DIR, \"Various_Tweets_(2023)_test.csv\"))\n",
        "vt_test  = pd.read_csv(os.path.join(DATA_DIR, \"Various_Tweets_(2023)_test.csv\"))\n",
        "\n",
        "# --- 2.2 Concatenate train, dev (validation), and test sets ---\n",
        "train_df = pd.concat([mtcsd_train, vast_train, ruw_train, vt_train], ignore_index=True)\n",
        "val_df   = pd.concat([mtcsd_dev, vast_dev, ruw_dev, vt_val], ignore_index=True)\n",
        "test_df  = pd.concat([mtcsd_test, vast_test, ruw_test, vt_test], ignore_index=True)\n",
        "\n",
        "# Sanity check\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Val size:  \", len(val_df))\n",
        "print(\"Test size: \", len(test_df))\n",
        "\n",
        "# Ensure columns are the same in each df\n",
        "print(\"Columns:\", train_df.columns.tolist())"
      ],
      "metadata": {
        "id": "YBhiffLPovAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. **Prepare the Data for Training**"
      ],
      "metadata": {
        "id": "EB2kuoB3pRY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_stance_to_label(stance):\n",
        "    \"\"\"\n",
        "    Original stance values: -1 (Against), 0 (None), 1 (Favor)\n",
        "    New label values: 0 -> 'Against', 1 -> 'None', 2 -> 'Favor'\n",
        "    \"\"\"\n",
        "    if stance == -1:\n",
        "        return 0\n",
        "    elif stance == 0:\n",
        "        return 1\n",
        "    elif stance == 1:\n",
        "        return 2\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected stance: {stance}\")\n",
        "\n",
        "def combine_inputs(row):\n",
        "    return f\"Target: {row['Target']} [SEP] Context: {row['Context']} [SEP] Text: {row['Text']}\"\n",
        "\n",
        "train_df[\"combined_text\"] = train_df.apply(combine_inputs, axis=1)\n",
        "val_df[\"combined_text\"]   = val_df.apply(combine_inputs, axis=1)\n",
        "test_df[\"combined_text\"]  = test_df.apply(combine_inputs, axis=1)\n",
        "\n",
        "train_df[\"label\"] = train_df[\"Stance\"].apply(map_stance_to_label)\n",
        "val_df[\"label\"]   = val_df[\"Stance\"].apply(map_stance_to_label)\n",
        "test_df[\"label\"]  = test_df[\"Stance\"].apply(map_stance_to_label)"
      ],
      "metadata": {
        "id": "EdgDSJucpPbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Huggingface Datasets\n",
        "hf_train = HFDataset.from_pandas(train_df[['combined_text', 'label']])\n",
        "hf_val   = HFDataset.from_pandas(val_df[['combined_text', 'label']])\n",
        "hf_test  = HFDataset.from_pandas(test_df[['combined_text', 'label']])"
      ],
      "metadata": {
        "id": "S7jcrExDp2PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. **Tokenize the Data**"
      ],
      "metadata": {
        "id": "1EpTVcbupvi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Features, Value\n",
        "\n",
        "model_name = \"dbmdz/bert-base-turkish-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"combined_text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128  # Adjust as needed\n",
        "    )\n",
        "\n",
        "hf_train = hf_train.map(tokenize_function, batched=True)\n",
        "hf_val   = hf_val.map(tokenize_function, batched=True)\n",
        "hf_test  = hf_test.map(tokenize_function, batched=True)\n",
        "\n",
        "hf_train = hf_train.remove_columns([\"combined_text\"])\n",
        "hf_val   = hf_val.remove_columns([\"combined_text\"])\n",
        "hf_test  = hf_test.remove_columns([\"combined_text\"])\n",
        "\n",
        "# Cast \"labels\" to int64\n",
        "from datasets import Value\n",
        "hf_train = hf_train.cast_column(\"label\", Value(\"int64\"))\n",
        "hf_val   = hf_val.cast_column(\"label\", Value(\"int64\"))\n",
        "hf_test  = hf_test.cast_column(\"label\", Value(\"int64\"))\n"
      ],
      "metadata": {
        "id": "LNTHzUy_psLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. **Create the Model**"
      ],
      "metadata": {
        "id": "h-isozwhqVR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)"
      ],
      "metadata": {
        "id": "ixhZyh3xqU7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. **Define Training Arguments and Trainer**"
      ],
      "metadata": {
        "id": "IZyQtKjdqflJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"output_dir\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    num_train_epochs=3,            # Adjust\n",
        "    per_device_train_batch_size=8, # Adjust\n",
        "    per_device_eval_batch_size=8,  # Adjust\n",
        "    warmup_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"wandb\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "\n",
        "    precision = precision_score(labels, preds, average=\"macro\")\n",
        "    recall = recall_score(labels, preds, average=\"macro\")\n",
        "    f1 = f1_score(labels, preds, average=\"macro\")\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"macro_precision\": precision,\n",
        "        \"macro_recall\": recall,\n",
        "        \"macro_f1\": f1\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=hf_train,\n",
        "    eval_dataset=hf_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "x_czlmyhqmxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "4tllx5JuqzSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. **Evaluate on Validation**"
      ],
      "metadata": {
        "id": "uG4qiQztqrLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_preds_output = trainer.predict(hf_val)\n",
        "val_logits = val_preds_output.predictions\n",
        "val_labels = val_preds_output.label_ids\n",
        "val_preds = np.argmax(val_logits, axis=-1)\n",
        "\n",
        "print(\"Validation classification report:\")\n",
        "print(classification_report(val_labels, val_preds, digits=3))"
      ],
      "metadata": {
        "id": "G_m-1ACrq-yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. **Evaluate on Test**\n",
        "\n"
      ],
      "metadata": {
        "id": "lZ2kZ--krEDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds_output = trainer.predict(hf_test)\n",
        "test_logits = test_preds_output.predictions\n",
        "test_labels = test_preds_output.label_ids\n",
        "test_preds = np.argmax(test_logits, axis=-1)\n",
        "\n",
        "print(\"Test classification report:\")\n",
        "print(classification_report(test_labels, test_preds, digits=3))"
      ],
      "metadata": {
        "id": "oyAueVqSrCyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "\n",
        "# Update the labels\n",
        "labels = [-1, 0, 1]\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix (on Test)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iUKwvF0GrcQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. **Precision-Recall Curves**"
      ],
      "metadata": {
        "id": "C12SLwiargvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_precision_recall_curves(logits, labels, num_classes=3):\n",
        "    \"\"\"Plot a separate Precision-Recall curve for each of the remapped classes (-1, 0, 1) in the correct order.\"\"\"\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
        "\n",
        "    # Mapping of original class indices to new ones\n",
        "    class_mapping = {1: -1, 0: 0, 2: 1}  # Original 0->0, 1->-1, 2->1\n",
        "    remapped_classes = sorted(class_mapping.values())  # Ensure the order is [-1, 0, 1]\n",
        "\n",
        "    # Reverse the mapping to align indices with remapped_classes\n",
        "    reverse_mapping = {v: k for k, v in class_mapping.items()}\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_classes, figsize=(5 * num_classes, 5), sharey=True)\n",
        "\n",
        "    for idx, remapped_class in enumerate(remapped_classes):\n",
        "        original_class = reverse_mapping[remapped_class]  # Get original class index\n",
        "        # Binarize: current class vs rest\n",
        "        y_true = (labels == original_class).astype(int)\n",
        "        y_scores = probs[:, original_class]\n",
        "\n",
        "        precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
        "        axes[idx].plot(recall, precision, label=f\"Class {remapped_class}\")\n",
        "        axes[idx].set_title(f\"Precision-Recall Curve (Class {remapped_class})\")\n",
        "        axes[idx].set_xlabel(\"Recall\")\n",
        "        axes[idx].set_ylabel(\"Precision\")\n",
        "        axes[idx].legend(loc=\"lower left\")\n",
        "        axes[idx].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot for the test set\n",
        "plot_precision_recall_curves(test_logits, test_labels, num_classes=3)"
      ],
      "metadata": {
        "id": "5SslckPJtTvj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}