{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDIagBmt6cR4"
      },
      "source": [
        "**Accessing via Huggingface API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jjIzEc2cW7PT",
        "outputId": "32dff3f9-a414-45d9-c75d-7d71a127b84c"
      },
      "outputs": [],
      "source": [
        "pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wABJtoQ1Hmb4",
        "outputId": "84bd0794-aec5-493d-8e70-3b30682577a3"
      },
      "outputs": [],
      "source": [
        "pip install pandas requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYVsK0jDHbFD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# -------------------------------------------------\n",
        "# CONFIGURATION\n",
        "# -------------------------------------------------\n",
        "HF_API_KEY = \"api_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
        "MODEL_ID = \"NousResearch/Hermes-3-Llama-3.1-8B\"\n",
        "\n",
        "# CSV splits to process\n",
        "csv_files = [\"input.csv\"]  # change according to the dataset\n",
        "\n",
        "# change according to the dataset\n",
        "DATASET_DESCRIPTION = \"VAST isimli, 2020 yılında oluşturulmuş bu dataset, The New York Times’in ‘Room for Debate’ bölümündeki yorumların etiketlenmesiyle hazırlanmış olup, özellikle tutum (stance) tespiti görevleri için tasarlanmıştır. Politika (örneğin, 'Filistin devleti'), eğitim (örneğin, 'imtiyazlı okullar') ve halk sağlığı (örneğin, 'çocukluk aşıları') gibi geniş temaları kapsayan çeşitli konuları kapsar. Ayrıca, ‘kampüste silahlar’ ile ‘kampüste ateşli silahlar’ gibi benzer ifadelerin bir arada bulunduğu örnekleri de içerir.\"\n",
        "\n",
        "# -------------------------------------------------\n",
        "# HELPER: Generate 'Context' text from model\n",
        "# -------------------------------------------------\n",
        "def generate_context(text, target):\n",
        "    \"\"\"\n",
        "    Calls the Hugging Face Inference API with the prompt\n",
        "    and returns the model's response as a string.\n",
        "    \"\"\"\n",
        "    # Build prompt\n",
        "    prompt = f\"\"\"Sosyal bir uzman olduğunu varsayarak, aşağıda {DATASET_DESCRIPTION} datasetinin kısa bir pasajı verilmiştir, lütfen adım adım düşün, metindeki anahtar kelimeleri çıkar, yazarın ima ettiği duyguları, retorik araçları vb. analiz et, son olarak yazarın Target hakkındaki duruşunu kısaca analiz et, sonuca varmadan analiz sürecini vermeye dikkat et. Ayrıca açıklama 100 kelimeyi geçmesin ve hiçbir şekilde link içermesin.\n",
        "Passage: {text}\n",
        "Target: {target}\n",
        "\"\"\"\n",
        "\n",
        "    # Prepare JSON payload for the HF Inference API\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": 500,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Make request\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {HF_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    HF_API_URL = f\"https://api-inference.huggingface.co/models/{MODEL_ID}\"\n",
        "\n",
        "    response = requests.post(HF_API_URL, headers=headers, json=payload)\n",
        "\n",
        "    # If no success, handle errors\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: {response.status_code}, {response.text}\")\n",
        "        return \"\"\n",
        "\n",
        "    data = response.json()\n",
        "    # data is typically [{\"generated_text\": \"...\"}]\n",
        "    if isinstance(data, list) and len(data) > 0 and \"generated_text\" in data[0]:\n",
        "        return data[0][\"generated_text\"]\n",
        "    elif isinstance(data, dict) and \"generated_text\" in data:\n",
        "        return data[\"generated_text\"]\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "# -------------------------------------------------\n",
        "# MAIN: For each CSV, add a \"Context\" column\n",
        "# -------------------------------------------------\n",
        "for csv_file in csv_files:\n",
        "    print(f\"Processing: {csv_file}\")\n",
        "    df = pd.read_csv(csv_file, encoding=\"utf-8\")\n",
        "\n",
        "    # create a new column \"Context\" by calling generate_context row by row.\n",
        "    context_list = []\n",
        "    for i, row in df.iterrows():\n",
        "        target_val = row[\"Target\"]\n",
        "        text_val = row[\"Text\"]\n",
        "\n",
        "        # Generate context from LLM\n",
        "        context_text = generate_context(text_val, target_val)\n",
        "\n",
        "\n",
        "        context_list.append(context_text)\n",
        "\n",
        "    # Add the new column\n",
        "    df[\"Context\"] = context_list\n",
        "\n",
        "    # Save the updated CSV\n",
        "    output_name = csv_file.replace(\".csv\", \"_with_context.csv\")\n",
        "    df.to_csv(output_name, index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"Saved: {output_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykXJxjKc6hwn"
      },
      "source": [
        "**Accessing Locally**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h0S6ouuo6o47",
        "outputId": "7c16c807-ce67-431a-d890-57ddb7204632"
      },
      "outputs": [],
      "source": [
        "pip install torch transformers accelerate sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kDJ0PL6i9yjn",
        "outputId": "0e642fc7-8387-48c4-f97e-281bec3fdc18"
      },
      "outputs": [],
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/NousResearch/Hermes-3-Llama-3.1-8B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "0a85adfed4df4ccba0c03d6b73731b2c",
            "9b3f1bed13034a3cba856f329ad22d9f",
            "b03468753cff49ec8ed41a092ff15611",
            "80ded8de1c774168b9d2c40d4797af28",
            "e83735d01e47463f8ed60f6f68bfaf4b",
            "a24c613e62f2495eb45a11c2b61a92f7",
            "4ea4c6c289be4f308c18d337f7126ebd",
            "561785e53e41408596ebd8a82a23d05a",
            "18c3b7d9d31c47f19f5015a5e3beb30d",
            "6495ce6380474d2eaabbee6df2586e7a",
            "147284d33327479ba769c224012f5bde"
          ]
        },
        "id": "IupXjGk--65O",
        "outputId": "49bba5ca-c0eb-4e81-e8fb-2c9288ffc54c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "############################\n",
        "# CONFIGURATION\n",
        "############################\n",
        "MODEL_PATH = \"model_path\"  # local folder with the model\n",
        "INPUT_CSV = \"input_csv_path\"  # input CSV with 'Text' and 'Target' columns         \n",
        "OUTPUT_CSV = \"output_csv_path\"     # output CSV with new 'Context' column\n",
        "\n",
        "# change according to the dataset\n",
        "DATASET_DESCRIPTION = (\n",
        "    \"VAST isimli, 2020 yılında oluşturulmuş bu dataset, The New York Times’in ‘Room for Debate’ bölümündeki yorumların \"\n",
        "    \"etiketlenmesiyle hazırlanmış olup, özellikle tutum (stance) tespiti görevleri için tasarlanmıştır. Politika (örneğin, 'Filistin devleti'),\"\n",
        "    \"eğitim (örneğin, 'imtiyazlı okullar') ve halk sağlığı (örneğin, 'çocukluk aşıları') gibi geniş temaları kapsayan çeşitli konuları kapsar. \"\n",
        "    \"Ayrıca, ‘kampüste silahlar’ ile ‘kampüste ateşli silahlar’ gibi benzer ifadelerin bir arada bulunduğu örnekleri de içerir.\"\n",
        ")\n",
        "\n",
        "############################\n",
        "# LOAD MODEL LOCALLY\n",
        "############################\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "print(\"Loading model...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    torch_dtype=torch.float16,  # or bfloat16, etc. adjust as needed\n",
        "    device_map=\"auto\",         # automatically map to GPU or CPU\n",
        ")\n",
        "\n",
        "############################\n",
        "# GENERATION FUNCTION\n",
        "############################\n",
        "def generate_context(text, target):\n",
        "    \"\"\"\n",
        "    Generates context from the local LLaMA model:\n",
        "    - No external links\n",
        "    - Under ~100 words\n",
        "    \"\"\"\n",
        "    # Prompt: no links, under 100 words\n",
        "    prompt = f\"\"\"\n",
        "Sosyal bir uzman olduğunu varsayarak, aşağıda {DATASET_DESCRIPTION} datasetinden\n",
        "kısa bir pasaj verilmiştir. Lütfen adım adım düşün, metindeki anahtar kelimeleri çıkar;\n",
        "yazarın ima ettiği duyguları, retorik araçları vb. analiz et;\n",
        "ve son olarak yazarın Target hakkındaki duruşuna dair kısa bir analiz yap, sonuca varmadan analiz sürecini vermeye dikkat et.\n",
        "Ayrıca açıklama 100 kelimeyi geçmesin ve hiçbir şekilde link içermesin.\n",
        "\n",
        "Passage: {text}\n",
        "Target: {target}\n",
        "\"\"\"\n",
        "\n",
        "    # Encode prompt\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    # Generate text\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,        # limit generation\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "    # Decode the entire output\n",
        "    full_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Separate out the part after the prompt\n",
        "    prompt_len = len(tokenizer.encode(prompt))\n",
        "    response = tokenizer.decode(output_ids[0][prompt_len:], skip_special_tokens=True)\n",
        "\n",
        "    # Optional: a quick post-process to ensure we don't exceed ~100 words\n",
        "    #   (model might still exceed if it doesn't follow instructions)\n",
        "    response_words = response.strip().split()\n",
        "    if len(response_words) > 100:\n",
        "        response = \" \".join(response_words[:100])\n",
        "\n",
        "    return response.strip()\n",
        "\n",
        "############################\n",
        "# MAIN FLOW\n",
        "############################\n",
        "def main():\n",
        "    print(f\"Reading input CSV: {INPUT_CSV}\")\n",
        "    df = pd.read_csv(INPUT_CSV, encoding=\"utf-8\")\n",
        "\n",
        "    if \"Text\" not in df.columns or \"Target\" not in df.columns:\n",
        "        raise ValueError(\"Input CSV must have 'Text' and 'Target' columns.\")\n",
        "\n",
        "    # Generate 'Context' for each row\n",
        "    contexts = []\n",
        "    for i, row in df.iterrows():\n",
        "        text_val = str(row[\"Text\"])\n",
        "        target_val = str(row[\"Target\"])\n",
        "        ctx = generate_context(text_val, target_val)\n",
        "        contexts.append(ctx)\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f\"Processed {i+1} rows...\")\n",
        "\n",
        "    df[\"Context\"] = contexts\n",
        "\n",
        "    # Save the output\n",
        "    print(f\"Saving to {OUTPUT_CSV}\")\n",
        "    df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
        "    print(\"Done!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a85adfed4df4ccba0c03d6b73731b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b3f1bed13034a3cba856f329ad22d9f",
              "IPY_MODEL_b03468753cff49ec8ed41a092ff15611",
              "IPY_MODEL_80ded8de1c774168b9d2c40d4797af28"
            ],
            "layout": "IPY_MODEL_e83735d01e47463f8ed60f6f68bfaf4b"
          }
        },
        "147284d33327479ba769c224012f5bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18c3b7d9d31c47f19f5015a5e3beb30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ea4c6c289be4f308c18d337f7126ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "561785e53e41408596ebd8a82a23d05a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6495ce6380474d2eaabbee6df2586e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80ded8de1c774168b9d2c40d4797af28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6495ce6380474d2eaabbee6df2586e7a",
            "placeholder": "​",
            "style": "IPY_MODEL_147284d33327479ba769c224012f5bde",
            "value": " 4/4 [01:19&lt;00:00, 26.41s/it]"
          }
        },
        "9b3f1bed13034a3cba856f329ad22d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a24c613e62f2495eb45a11c2b61a92f7",
            "placeholder": "​",
            "style": "IPY_MODEL_4ea4c6c289be4f308c18d337f7126ebd",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a24c613e62f2495eb45a11c2b61a92f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03468753cff49ec8ed41a092ff15611": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_561785e53e41408596ebd8a82a23d05a",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18c3b7d9d31c47f19f5015a5e3beb30d",
            "value": 4
          }
        },
        "e83735d01e47463f8ed60f6f68bfaf4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
