{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNTayAFo6qsoMCubGYf8V9G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etqG0MAhT7fo","executionInfo":{"status":"ok","timestamp":1735706604810,"user_tz":-180,"elapsed":1344,"user":{"displayName":"Nur Efşan Delikkaya (Student)","userId":"07973742884581158941"}},"outputId":"c912c33f-85d1-4b15-9d51-b8faa33611e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['yazar', ' postalamak', ' ori_konu', ' ori_id', ' yeni_konu', ' etiket',\n","       ' tür_idx', ' yeni_kimlik', ' yay_kimliği', ' metin', ' konum_metni',\n","       ' metin_ler', ' başlık', ' konu_str', ' görülen?', ' içerik_konu?'],\n","      dtype='object')\n"]}],"source":["text_df = pd.read_excel(\"/content/vast_dev_translated.xlsx\", dtype=str)\n","print(text_df.columns)"]},{"cell_type":"markdown","source":["author,post,ori_topic,ori_id,new_topic,label,type_idx,new_id,arc_id,text,pos_text,text_s,topic,topic_str,seen?,contains_topic?\n","\n","\n","\n","*   author: username of the comment author\n","*   post: original comment, unprocessed\n","*   ori_id: id generated to link post and heuristically extracted topics\n","*   new_id: unique id for every comment-topic-label pair\n","*   arc_id: id of the original article on NYT\n","*   text: sentence and word tokenized and lowercased text, with punctuation and stopwords removed\n","*   change_lst: list of swapped words (unique to vast_test-sentswap.csv)\n","*   change_type: type of sentiment swapping\n","*   LexSim: a list of lexically similar training topics (if a zero-shot topic)\n","*   Qte: whether the example contains quotes (1=yes, 0=no)\n","*   Sarc: whether the example contains sarcasm (1=yes, 0=no)\n","*   Imp: whether the text contains the topic and the label is non-neutral (1=yes, 0=no)\n","*  mlS: whether there are other examples with the same document and different, non-neutral, stance labels (1=yes, 0=no)\n","*  mlT: whether there are other examples with the same document and different topics (1=yes, 0=no)\n","*   ori_topic: heuristically extracted topic\n","*   new_topic: updated topic from crowdsourced annotations\n","*   type_idx: type number, 1=HeurTopic, 2=CorrTopic, 3=ListTopic, 4=Synthetic neutral\n","*   topic: tokenized and lowercased version topic, with punctuation and stopwords removed\n","*   seen?: indicator for zero-shot or few-shot example, 0=zero-shot, 1=few-shot\n","*   contains_topic?: indicator for whether topic is contained in the text, 0=no, 1=yes\n","\n","\n","**label: stance label, 0=con, 1=pro, 2=neutral**\n","**text_s: string version of text**\n","**topic_str: string version of topic**\n","\n","\n"],"metadata":{"id":"WgvIF-FOVgWH"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# List of your 5 XLSX input files\n","xlsx_files = [\n","    \"/content/vast_dev_translated.xlsx\",\n","    \"/content/vast_train_translated.xlsx\",\n","    \"/content/vast_test_translated.xlsx\"\n","\n","]\n","\n","# A list to collect data from all 5 files\n","all_data = []\n","\n","for xlsx_path in xlsx_files:\n","    # 1) Read the XLSX into a DataFrame\n","    df = pd.read_excel(xlsx_path, dtype=str)\n","\n","    # 2) Convert stance from str to numeric where possible\n","    #    'etiket' might be \"0\", \"1\", or \"2\" in text form.\n","    #    We'll force it to numeric type for mapping.\n","    df[\" etiket\"] = pd.to_numeric(df[\" etiket\"], errors=\"coerce\")\n","\n","    # 3) Map the numeric stance to the new scheme:\n","    #       original → new\n","    #       0=against → -1\n","    #       1=favor   →  1\n","    #       2=none    →  0\n","    def map_stance(value):\n","        if value == 0:\n","            return -1   # against\n","        elif value == 1:\n","            return 1    # favor\n","        elif value == 2:\n","            return 0    # none\n","        return None     # fallback if missing\n","\n","    df[\"etiket_mapped\"] = df[\" etiket\"].apply(map_stance)\n","\n","    # 4) Subset the columns we want: topic_str, etiket_mapped, text_s\n","    subset_df = df[[\" konu_str\", \"etiket_mapped\", \" postalamak\"]].copy()\n","\n","    # 5) Rename columns to [Target, Stance, Text]\n","    subset_df.rename(\n","        columns={\n","            \" konu_str\": \"Target\",\n","            \"etiket_mapped\": \"Stance\",\n","            \" postalamak\": \"Text\"\n","        },\n","        inplace=True\n","    )\n","\n","    # 6) Append to all_data\n","    all_data.append(subset_df)\n","\n","# 7) Concatenate all 5 dataframes\n","final_df = pd.concat(all_data, ignore_index=True)\n","\n","# 8) Save to CSV\n","output_csv = \"VAST_stance.csv\"\n","final_df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n","\n","print(f\"Done! Created {output_csv} with {len(final_df)} rows.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rx0n72hIVoYw","executionInfo":{"status":"ok","timestamp":1735706997170,"user_tz":-180,"elapsed":6726,"user":{"displayName":"Nur Efşan Delikkaya (Student)","userId":"07973742884581158941"}},"outputId":"6192bdfb-5cd4-4e86-8320-7eccfea16bd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Done! Created VAST_stance.csv with 18545 rows.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# 1. Read the processed CSV\n","df = pd.read_csv(\"/content/VAST_stance.csv\", encoding=\"utf-8\")\n","\n","# 2. Split DF into train (70%) and temp (30%)\n","train_df, temp_df = train_test_split(\n","    df,\n","    test_size=0.30,   # 30% goes to temp\n","    random_state=42,  # for reproducible splits\n","    shuffle=True\n",")\n","\n","# 3. Split temp_df into test (15%) and dev (15%)\n","#    Since temp_df is 30% of the total, half of it is 15% of the total.\n","test_df, dev_df = train_test_split(\n","    temp_df,\n","    test_size=0.5,    # half of temp => 15% of entire dataset\n","    random_state=42,\n","    shuffle=True\n",")\n","\n","# 4. Save each split\n","train_df.to_csv(\"VAST_train.csv\", index=False, encoding=\"utf-8-sig\")\n","test_df.to_csv(\"VAST_test.csv\", index=False, encoding=\"utf-8-sig\")\n","dev_df.to_csv(\"VAST_dev.csv\", index=False, encoding=\"utf-8-sig\")\n","\n","print(f\"Train size: {len(train_df)} rows\")\n","print(f\"Test size: {len(test_df)} rows\")\n","print(f\"Dev size: {len(dev_df)} rows\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YQZTC8ZhGW9a","executionInfo":{"status":"ok","timestamp":1735722238997,"user_tz":-180,"elapsed":3479,"user":{"displayName":"Nur Efşan Delikkaya (Student)","userId":"07973742884581158941"}},"outputId":"f6d60c6b-79de-46db-cd72-19bb11ebc683"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Train size: 12981 rows\n","Test size: 2782 rows\n","Dev size: 2782 rows\n"]}]}]}